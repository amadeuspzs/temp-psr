{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Interview Exercise - Senior Data Scientist - Computer Vision (Contractor).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOkd4GVT3x7nJ9tmkXX8kNb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1z3ds7qogZmA"},"source":["# Interview Exercise - Senior Data Scientist Computer Vision - Interview\n","\n","---\n","\n","\n","\n","## Introduction\n","\n","This notebook contains a short (15 minute) series of exercises to assist in identifying a **Data Scientist - Computer Vision Contractor** for the NHS AI Lab Skunkworks SWAT team.\n","\n","### What is a SWAT Team?\n","\n","A SWAT team is a rapid action team spun up to assist an NHS organisation, such as a trust, build and/or implement an AI solution. This may be a new project built from scratch, or a continuation of a project that we have released as Open Source on our [Github](https://github.com/nhsx).\n","\n","### What is the goal of this exercise?\n","\n","This is not a Google coding interview. The goal is to ensure sufficient proficiency with the data science tools required for this project, but above all, the **ability to learn quickly, and experiment**.\n","\n","* Feel free to Google/Stackoverflow for help during this process (\"open book\")\n","* Don't worry about completing all the exercises during this interview.\n","\n","## Instructions\n","\n","You will be presented with a number of activities. Take your time to read through the instructions and let your interviewer know when you are ready to start.\n","\n","\n","## Exercise 1 - Working with DICOM files\n","\n","This project will involve working with DICOM files.\n","\n","Using the [pydicom](https://github.com/pydicom/pydicom) library, load the `CT_small.dcm` sample and plot it."]},{"cell_type":"code","metadata":{"id":"YXyHL5V1MCFG"},"source":["pip install matplotlib pydicom"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoC0745ggMrY"},"source":["import matplotlib.pyplot as plt\n","from pydicom import dcmread\n","from pydicom.data import get_testdata_file\n","\n","# The path to a pydicom test dataset\n","path = get_testdata_file(\"CT_small.dcm\")\n","ds = dcmread(path)\n","# `arr` is a numpy.ndarray\n","arr = ds.pixel_array\n","\n","plt.imshow(arr, cmap=\"gray\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1XIcWtwiBRc"},"source":["Our projects typically do not include personal data in line with GDPR and a Data Protection Impact Assessment (DPIA) completed ahead of time.\n","\n","Can you check for personal data in the test dataset?"]},{"cell_type":"code","metadata":{"id":"Rv-KdXG3h-5f"},"source":["ds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvaUbYPdSfD6"},"source":["## Exercise 2 - Working with DICOM slices\n","\n","We are going to work with CT data, which comprises of multiple \"slices\" per scan.\n","\n","We're going to start by loading the slice data from [PCIR](http://www.pcir.org/researchers/54879843_20060101.html) which we have downloaded locally:\n"]},{"cell_type":"code","metadata":{"id":"BmnVESb1Oyr-"},"source":["from google.colab import drive\n","import glob\n","import numpy as np\n","\n","\n","drive.mount('/content/gdrive')\n","slice_data_path=\"/content/gdrive/Shareddrives/NHS AI Lab & Team/Skunkworks/Projects and procurement/2 SWAT projects/sample_data/DICOM/Crane SPC/\"\n","\n","# load the DICOM files\n","files = []\n","for fname in glob.glob(slice_data_path + \"*\", recursive=False):\n","    print(\"loading: {}\".format(fname))\n","    files.append(dcmread(fname))\n","\n","print(\"file count: {}\".format(len(files)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EtgIGWaJSo9x"},"source":["# skip files with no SliceLocation (eg scout views)\n","slices = []\n","skipcount = 0\n","for f in files:\n","    if hasattr(f, 'SliceLocation'):\n","        slices.append(f)\n","    else:\n","        skipcount = skipcount + 1\n","\n","print(\"skipped, no SliceLocation: {}\".format(skipcount))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ILS2LApUAHx"},"source":["# ensure they are in the correct order\n","slices = sorted(slices, key=lambda s: s.SliceLocation)\n","\n","# pixel aspects, assuming all slices are the same\n","ps = slices[0].PixelSpacing\n","ss = slices[0].SliceThickness\n","ax_aspect = ps[1]/ps[0]\n","sag_aspect = ps[1]/ss\n","cor_aspect = ss/ps[0]\n","\n","# create 3D array\n","img_shape = list(slices[0].pixel_array.shape)\n","img_shape.append(len(slices))\n","img3d = np.zeros(img_shape)\n","\n","# fill 3D array with the images from the files\n","for i, s in enumerate(slices):\n","    img2d = s.pixel_array\n","    img3d[:, :, i] = img2d\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E9o6bjnNXb7_"},"source":["# plot 3 orthogonal slices\n","a1 = plt.subplot(2, 2, 1)\n","plt.imshow(img3d[:, :, img_shape[2]//2])\n","a1.set_aspect(ax_aspect)\n","\n","a2 = plt.subplot(2, 2, 2)\n","plt.imshow(img3d[:, img_shape[1]//2, :])\n","a2.set_aspect(sag_aspect)\n","\n","a3 = plt.subplot(2, 2, 3)\n","plt.imshow(img3d[img_shape[0]//2, :, :].T)\n","a3.set_aspect(cor_aspect)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lFGRlCBMuKN8"},"source":["from ipywidgets import interact\n","plt.figure(1)\n","def dicom_animation(x):\n","    plt.imshow(slices[x].pixel_array, cmap = plt.cm.gray)\n","    return x\n","interact(dicom_animation, x=(0, len(slices)-1));"],"execution_count":null,"outputs":[]}]}